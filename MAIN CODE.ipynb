{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" mean and STANDARD DEVIATION\"\"\"\n",
    "mat = loadmat('rawSensorData_train.mat')\n",
    "print(mat.keys()) # Table 3\n",
    "print(type(mat['body_gyro_x_train']), mat['body_gyro_x_train'].shape)\n",
    "bx = mat['body_gyro_x_train'] # this is a numpy array\n",
    "by = mat['body_gyro_y_train']\n",
    "bz = mat['body_gyro_z_train']\n",
    "bx_mean = np.mean(bx, axis=1)\n",
    "by_mean = np.mean(by, axis=1)\n",
    "bz_mean = np.mean(bz, axis=1)\n",
    "bx_std = np.std(bx, axis=1)\n",
    "by_std = np.std(by, axis=1)\n",
    "bz_std = np.std(bz, axis=1)\n",
    "ax = mat['total_acc_x_train']\n",
    "ay = mat['total_acc_y_train']\n",
    "az = mat['total_acc_z_train']\n",
    "ax_mean = np.mean(ax, axis=1)\n",
    "ay_mean = np.mean(ay, axis=1)\n",
    "az_mean = np.mean(az, axis=1)\n",
    "ax_std = np.std(ax, axis=1)\n",
    "ay_std = np.std(ay, axis=1)\n",
    "az_std = np.std(az, axis=1)\n",
    "mat = loadmat('rawSensorData_test.mat')\n",
    "ax_t = mat['total_acc_x_test']\n",
    "ay_t = mat['total_acc_y_test']\n",
    "az_t = mat['total_acc_z_test']\n",
    "ax_mean_t = np.mean(ax_t, axis=1)\n",
    "ay_mean_t = np.mean(ay_t, axis=1)\n",
    "az_mean_t = np.mean(az_t, axis=1)\n",
    "ax_std_t = np.std(ax_t, axis=1)\n",
    "ay_std_t = np.std(ay_t, axis=1)\n",
    "az_std_t = np.std(az_t, axis=1)\n",
    "bx_t = mat['body_gyro_x_test'] # this is a numpy array\n",
    "by_t = mat['body_gyro_y_test']\n",
    "bz_t = mat['body_gyro_z_test']\n",
    "bx_mean_t = np.mean(bx_t, axis=1)\n",
    "by_mean_t = np.mean(by_t, axis=1)\n",
    "bz_mean_t = np.mean(bz_t, axis=1)\n",
    "bx_std_t = np.std(bx_t, axis=1)\n",
    "by_std_t = np.std(by_t, axis=1)\n",
    "bz_std_t = np.std(bz_t, axis=1)\n",
    "“”3d plotting for train data””\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATINATION DONE FOR THE TRAINING AND TEST SETS\n",
    "X_train1 = np.array(\n",
    "[ax_mean, ay_mean, az_mean, ax_std, ay_std, az_std, bx_mean, by_mean, bz_mean, bx_std,\n",
    "by_std, bz_std])\n",
    "X_train1 = X_train1.transpose()\n",
    "X_test1 = np.array(\n",
    "[ax_mean_t, ay_mean_t, az_mean_t, ax_std_t, ay_std_t, az_std_t, bx_mean_t, by_mean_t,\n",
    "bz_mean_t, bx_std_t, by_std_t,\n",
    "bz_std_t])\n",
    "X_test1 = X_test1.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the labels.\n",
    "mat2 = loadmat('labels.mat')\n",
    "train_labels = mat2['train_labels']\n",
    "test_labels = mat2['test_labels']\n",
    "labelss = bx_mean\n",
    "for i in range(0, 7352):\n",
    "labelss[i] = train_labels[i][0]\n",
    "# encode/transform so the class starts at 0 to 4 rather than 1 to 5.\n",
    "# aside: the onehot encoding doesnt start from 0 so we get 6 classes if we don't do this.\n",
    "dict = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n",
    "train_labels = np.vectorize(dict.get)(train_labels)\n",
    "test_labels = np.vectorize(dict.get)(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize what one sample looks like, with class label\n",
    "plt.subplot(331)\n",
    "plt.plot(ax[0, :])\n",
    "plt.title(['sample for Hand extension game:', train_labels[0][0]])\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Normalized Acceleration')# 3\n",
    "plt.show()\n",
    "plt.subplot(333)\n",
    "plt.plot(ax[100, :])\n",
    "plt.title(['sample for Box and Block test game: ', train_labels[100][0]]) # 4\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Normalized Acceleration')\n",
    "plt.show()\n",
    "plt.subplot(335)\n",
    "plt.plot(ax[400, :])\n",
    "plt.title(['sample for Water bottle handling game: ', train_labels[400][0]]) # 1\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Normalized Acceleration')\n",
    "plt.show()\n",
    "plt.subplot(337)\n",
    "plt.plot(ax[150, :])\n",
    "plt.title(['sample for fork handling game: ', train_labels[150][0]]) # 2\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Normalized Acceleration')\n",
    "plt.show()\n",
    "plt.subplot(339)\n",
    "plt.plot(ax[240, :])\n",
    "plt.title(['sample for Writing game: ', train_labels[240][0]]) # 0\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Normalized Acceleration')\n",
    "plt.show()\n",
    "X_train1 = np.array([ax_mean, ay_mean, az_mean, labelss])\n",
    "X_train1 = X_train1.transpose()\n",
    "X_train2 = X_train1[X_train1[:, 3].argsort()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 3d Visualization\"\"\"\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter(X_train2[0:1406, 0], X_train2[0:1406, 1], X_train2[0:1406, 2]) # 1 BLUE BEST\n",
    "ax.scatter(X_train2[1407:2692, 0], X_train2[1407:2692, 1], X_train2[1407:2692, 2]) # 2\n",
    "ORANGE 2ND\n",
    "ax.scatter(X_train2[2693:4751, 0], X_train2[2693:4751, 1], X_train2[2693:4751, 2]) # 3\n",
    "GREEN BAD\n",
    "ax.scatter(X_train2[4752:6125, 0], X_train2[4752:6125, 1], X_train2[4752:6125, 2]) # 4 RED\n",
    "BAD\n",
    "ax.scatter(X_train2[6126:7352, 0], X_train2[6126:7352, 1], X_train2[6126:7352, 2]) # 5\n",
    "PURPLE BAD\n",
    "plt.ylabel('ay mean value')\n",
    "plt.xlabel('ax mean value')\n",
    "# plt.zlabel('az mean value')\n",
    "plt.legend(['Hand Extension Game', 'Box and Block test game', 'Water Bottle Handling game',\n",
    "'Fork Handling game', 'Writing game'], loc='upper left')\n",
    "plt.title('3D Visualization: mean accelerometer values with the corresponding label.')\n",
    "plt.show()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import pi\n",
    "from scipy.fftpack import fft\n",
    "sample_rate = 2048\n",
    "N = (2 ‐ 0) * sample_rate\n",
    "frequency = np.linspace (0.0, 50, int (N/2))\n",
    "freq_data1 = fft(X_train2[0:1406, :])\n",
    "y1 = 2/N * np.abs (freq_data1 [0:np.int (N/2)])\n",
    "plt.subplot(331)\n",
    "plt.plot(frequency[0:1406], y1)\n",
    "plt.title('Frequency domain Signal')\n",
    "plt.xlabel('Frequency in Hz\\n (a)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['X attribute','Y attribute','Z attribute'], loc= 'upper left', prop={\"size\":4})\n",
    "plt.show()\n",
    "plt.subplot(333)\n",
    "freq_data2 = fft(X_train2[1407:2692, :])\n",
    "y2 = 2/N * np.abs (freq_data2 [0:np.int (N/2)])\n",
    "plt.plot(frequency[0:1285], y2)\n",
    "plt.title('Frequency domain Signal')\n",
    "plt.xlabel('Frequency in Hz\\n (b)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['X attribute','Y attribute','Z attribute'], loc= 'upper left',prop={\"size\":4})\n",
    "plt.show()\n",
    "freq_data3 = fft(X_train2[2693:4751, :])\n",
    "y3 = 2/N * np.abs (freq_data3 [0:np.int (N/2)])\n",
    "plt.subplot(335)\n",
    "plt.plot(frequency[0:2058], y3)\n",
    "plt.title('Frequency domain Signal')\n",
    "plt.xlabel('Frequency in Hz\\n (c)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['X attribute','Y attribute','Z attribute'], loc= 'upper left', prop={\"size\":4})\n",
    "plt.show()\n",
    "freq_data4 = fft(X_train2[4752:6125, :])\n",
    "y4 = 2/N * np.abs (freq_data4 [0:np.int (N/2)])\n",
    "plt.subplot(337)\n",
    "plt.plot(frequency[0:1373], y4)\n",
    "plt.title('Frequency domain Signal')\n",
    "plt.xlabel('Frequency in Hz\\n (d)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['X attribute','Y attribute','Z attribute'], loc= 'upper left', prop={\"size\":4})\n",
    "plt.show()\n",
    "freq_data5 = fft(X_train2[6126:7352, :])\n",
    "y5 = 2/N * np.abs (freq_data5 [0:np.int (N/2)])\n",
    "plt.subplot(339)\n",
    "plt.plot(frequency[0:1226], y5)\n",
    "plt.title('Frequency domain Signal')\n",
    "plt.xlabel('Frequency in Hz\\n (e)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend(['X attribute','Y attribute','Z attribute'], loc= 'upper left', prop={\"size\":4})\n",
    "plt.show()\n",
    "\"\"\"Standardize the 12 features for test and train\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "sc = ss()\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "X_test1 = sc.transform(X_test1)\n",
    "# one hot encoding\n",
    "from keras import regularizers, optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "# convert to one‐hot\n",
    "train_labels_enc = to_categorical(train_labels)\n",
    "test_labels_enc = to_categorical(test_labels)\n",
    "# parameters for neural net\n",
    "num_inputs = X_train1.shape[1] # Total number 0f input variables (per sample)\n",
    "num_labels = train_labels_enc.shape[1] # Total number of output labels ‐ 3.\n",
    "# one hot encoding: so label 0 is [1 0 0]. label 1 is [0 1 0], label 2 is [0 0 1],\n",
    "# build neural net model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(num_inputs,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128, kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# We can have a validation set, which is a fraction of the training set used to validate\n",
    "our model.\n",
    "history = model.fit(X_train1, train_labels_enc, validation_split=0.3, epochs=30)\n",
    "test_loss, test_acc = model.evaluate(X_test1, test_labels_enc, verbose=2)\n",
    "print('\\nTest loss:', test_loss)\n",
    "print('\\nTest accuracy:', test_acc) # loss=0.43445313055716733\n",
    "y_pred_test = model.predict(X_test1)\n",
    "y_pred_train = model.predict(X_train1)\n",
    "for i in range(0, 2947): # need to convert back to labels, undo one hot encoding\n",
    "for j in range(0, 5): # need 0 0 0 1 and not probabilities to undo encoding\n",
    "if y_pred_test[i][j] > 0.5:\n",
    "y_pred_test[i][j] = 1\n",
    "else:\n",
    "y_pred_test[i][j] = 0\n",
    "for i in range(0, 7352):\n",
    "for j in range(0, 5):\n",
    "if y_pred_train[i][j] > 0.5:\n",
    "y_pred_train[i][j] = 1\n",
    "else:\n",
    "y_pred_train[i][j] = 0\n",
    "class_labels = np.argmax(y_pred_test, axis=1)\n",
    "class_train_labels = np.argmax(y_pred_train, axis=1)\n",
    "\"CONFUSION MATRIX\"\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_test = confusion_matrix(class_labels, test_labels)\n",
    "cm_train = confusion_matrix(class_train_labels, train_labels)\n",
    "print(\"the confusion matrix for test set using Neural Networks\")\n",
    "print(cm_test)\n",
    "print(\"the confusion matrix for train set using Neuram Networks\")\n",
    "print(cm_train)\n",
    "print('Accuracy for test set using NN = {}'.format((np.trace(cm_test)) /\n",
    "len(class_labels)))\n",
    "print('Accuracy for training using NN= {}'.format((np.trace(cm_train)) /\n",
    "len(class_train_labels)))\n",
    "df_conf_norm = cm_test / cm_test.sum(axis=1)\n",
    "df_conf_norm = np.around((cm_test / cm_test.sum(axis=1)))\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix without\n",
    "norm', cmap=plt.cm.Blues):\n",
    "blank_array = [[‐1 for i in range(len(classes))]]\n",
    "cm = np.concatenate((blank_array, cm, blank_array))\n",
    "gm = cm[1:6, :]\n",
    "if normalize:\n",
    "gm = gm.astype('float') / gm.sum(axis=1)[:, np.newaxis]\n",
    "print(\"Normalized confusion matrix\")\n",
    "else:\n",
    "print('Confusion matrix, without normalization')\n",
    "print(gm)\n",
    "plt.imshow(gm, interpolation='nearest', cmap=cmap, aspect='auto')\n",
    "plt.title(title)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "plt.yticks(tick_marks, classes, rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "fmt = '.2f' if normalize else 'd'\n",
    "thresh = gm.max() / 2.\n",
    "for i, j in itertools.product(range(gm.shape[0]), range(gm.shape[1])):\n",
    "plt.text(j, i,format(gm[i, j], fmt), fontsize=8, horizontalalignment=\"center\",\n",
    "va=\"center\",\n",
    "color=\"white\" if gm[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "names = ('Hand \\nExtension \\n Game', 'Box and \\nBlock\\n test \\n game', 'Water \\nBottle\n",
    "\\nHandling \\n game', 'Fork \\nHandling \\ngame', 'Writing \\n game')\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.tight_layout()\n",
    "plot_confusion_matrix(cm_train, names)\n",
    "print(history.history.keys())\n",
    "# Plot it ‐ we can see \"convergence\" or \"not yet...weights are changing a lot still, loss\n",
    "still can go lower\"\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy']) # if validation_split>0\n",
    "plt.title('Model TRAIN accuracy')\n",
    "plt.ylabel('Accuracy') # accuracy=0.8527315855026245\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "# Plot training & validation loss values\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss']) # if validation_split>0\n",
    "plt.title('Model TRAIN loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "##SVM IMPLEMENTATION\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "mat = loadmat('rawSensorData_train.mat')\n",
    "print(mat.keys()) # Table 3\n",
    "print(type(mat['body_gyro_x_train']), mat['body_gyro_x_train'].shape)\n",
    "bx = mat['body_gyro_x_train']\n",
    "by = mat['body_gyro_y_train']\n",
    "bz = mat['body_gyro_z_train']\n",
    "bx_mean = np.mean(bx, axis=1)\n",
    "by_mean = np.mean(by, axis=1)\n",
    "bz_mean = np.mean(bz, axis=1)\n",
    "bx_std = np.std(bx, axis=1)\n",
    "by_std = np.std(by, axis=1)\n",
    "bz_std = np.std(bz, axis=1)\n",
    "ax = mat['total_acc_x_train']\n",
    "ay = mat['total_acc_y_train']\n",
    "az = mat['total_acc_z_train']\n",
    "ax_mean = np.mean(ax, axis=1)\n",
    "ay_mean = np.mean(ay, axis=1)\n",
    "az_mean = np.mean(az, axis=1)\n",
    "ax_std = np.std(ax, axis=1)\n",
    "ay_std = np.std(ay, axis=1)\n",
    "az_std = np.std(az, axis=1)\n",
    "# print('gyroscope x training data shape', by.shape) #7352,128\n",
    "mat = loadmat('rawSensorData_test.mat')\n",
    "ax_t = mat['total_acc_x_test']\n",
    "ay_t = mat['total_acc_y_test']\n",
    "az_t = mat['total_acc_z_test']\n",
    "ax_mean_t = np.mean(ax_t, axis=1)\n",
    "ay_mean_t = np.mean(ay_t, axis=1)\n",
    "az_mean_t = np.mean(az_t, axis=1)\n",
    "ax_std_t = np.std(ax_t, axis=1)\n",
    "ay_std_t = np.std(ay_t, axis=1)\n",
    "az_std_t = np.std(az_t, axis=1)\n",
    "bx_t = mat['body_gyro_x_test']\n",
    "by_t = mat['body_gyro_y_test']\n",
    "bz_t = mat['body_gyro_z_test']\n",
    "bx_mean_t = np.mean(bx_t, axis=1)\n",
    "by_mean_t = np.mean(by_t, axis=1)\n",
    "bz_mean_t = np.mean(bz_t, axis=1)\n",
    "bx_std_t = np.std(bx_t, axis=1)\n",
    "by_std_t = np.std(by_t, axis=1)\n",
    "bz_std_t = np.std(bz_t, axis=1)\n",
    "# print('accelerometer x test data shape', ay_t.shape)\n",
    "# CONCATING TO GET THE FEATURE VECTOR TRAIN and test\n",
    "X_train1 = np.array(\n",
    "[ax_mean, ay_mean, az_mean, ax_std, ay_std, az_std, bx_mean, by_mean, bz_mean, bx_std,\n",
    "by_std, bz_std])\n",
    "X_train1 = X_train1.transpose()\n",
    "X_test1 = np.array(\n",
    "[ax_mean_t, ay_mean_t, az_mean_t, ax_std_t, ay_std_t, az_std_t, bx_mean_t, by_mean_t,\n",
    "bz_mean_t, bx_std_t, by_std_t,\n",
    "bz_std_t])\n",
    "X_test1 = X_test1.transpose()\n",
    "# obtain the labels. [laying, sitting, climbingstairs, standing, walking] from 1 to 5.\n",
    "mat2 = loadmat('labels.mat')\n",
    "train_labels = mat2['train_labels']\n",
    "test_labels = mat2['test_labels']\n",
    "# encode/transform so the class starts at 0 to 4 rather than 1 to 5.\n",
    "# aside: the onehot encoding doesnt start from 0 so we get 6 classes if we don't do this.\n",
    "dict = {1: 0, 2: 1, 3: 2, 4: 3, 5: 4}\n",
    "train_labels = np.vectorize(dict.get)(train_labels)\n",
    "test_labels = np.vectorize(dict.get)(test_labels)\n",
    "\"\"\"Standardize the 12 features for test and train\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler as ss\n",
    "sc = ss()\n",
    "X_train1 = sc.fit_transform(X_train1)\n",
    "X_test1 = sc.transform(X_test1)\n",
    "# one hot encoding\n",
    "from sklearn import svm\n",
    "svm_classifier = svm.SVC(gamma='scale', kernel='rbf', probability=True)\n",
    "svm_classifier.fit(X_train1, train_labels.ravel())\n",
    "y_pred = svm_classifier.predict(X_test1) # predict class of test data\n",
    "from sklearn.metrics import confusion_matrix, average_precision_score\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "(\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "disp = plot_confusion_matrix(svm_classifier, X_test1, test_labels,\n",
    "display_labels=['Hand \\nExtension \\n Game', 'Box and\n",
    "\\nBlock\\n test \\n game', 'Water \\nBottle \\nHandling \\n game', 'Fork \\nHandling \\ngame',\n",
    "'Writing \\n game'],\n",
    "cmap=plt.cm.Blues,\n",
    "normalize=normalize)\n",
    "disp.ax_.set_title(title)\n",
    "print(title)\n",
    "print(disp.confusion_matrix)\n",
    "plt.show()\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
    "(\"Normalized confusion matrix\", 'true')]\n",
    "for title, normalize in titles_options:\n",
    "disp = plot_confusion_matrix(svm_classifier, X_train1, train_labels,\n",
    "display_labels=['Hand \\nExtension \\n Game', 'Box and\n",
    "\\nBlock\\n test \\n game', 'Water \\nBottle \\nHandling \\n game', 'Fork \\nHandling \\ngame',\n",
    "'Writing \\n game'],\n",
    "cmap=plt.cm.Blues,\n",
    "normalize=normalize)\n",
    "disp.ax_.set_title(title)\n",
    "print(title)\n",
    "print(disp.confusion_matrix)\n",
    "plt.show()\n",
    "cm_test = confusion_matrix(y_pred, test_labels)\n",
    "y_pred_train = svm_classifier.predict(X_train1)\n",
    "cm_train = confusion_matrix(y_pred_train, train_labels)\n",
    "print(cm_test.sum(axis=0))\n",
    "print(cm_test.sum(axis=1))\n",
    "print(np.diag(cm_test))\n",
    "print(np.diag(cm_test))\n",
    "FP = cm_test.sum(axis=0) ‐ np.diag(cm_test)\n",
    "FN = cm_test.sum(axis=1) ‐ np.diag(cm_test)\n",
    "TP = np.diag(cm_test)\n",
    "TN = cm_test.sum() ‐ (FP + FN + TP)\n",
    "# False positive rate\n",
    "FPR = FP / (FP + TN)\n",
    "print(\"FALSE POSITIVE RATE\")\n",
    "FPR1=list(map('{:.2f}'.format,map(float,(FPR))))\n",
    "print(FPR)\n",
    "# False negative rate\n",
    "FNR = FN / (TP + FN)\n",
    "print(\"FALSE NEGATIVE RATE\")\n",
    "FNR1=list(map('{:.2f}'.format,map(float,(FNR))))\n",
    "print(FNR)\n",
    "# True positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "print(\" True Positive Rate\")\n",
    "TPR1=list(map('{:.2f}'.format,map(float,(TPR))))\n",
    "print(TPR)\n",
    "# True Negative Rate\n",
    "TNR= 1‐FPR\n",
    "print(\"True Negative Rate\")\n",
    "TNR1=list(map('{:.2f}'.format,map(float,(TNR))))\n",
    "print(TNR)\n",
    "# Specifity\n",
    "Specifity= TN/(TN + FP)\n",
    "print(\"Specifity\")\n",
    "print(Specifity)\n",
    "Specifity1=list(map('{:.2f}'.format,map(float,(Specifity))))\n",
    "# Negative predictive value/ Negative precision\n",
    "NPV= TN/(TN + FN)\n",
    "print(\"Negative predictive value/ Negative precision:\")\n",
    "NPV1=list(map('{:.2f}'.format,map(float,(NPV))))\n",
    "print(NPV)\n",
    "#Positive likelihood ratio\n",
    "PLR= TPR/FPR\n",
    "#PLR=list(map('{:.2f}'.format,PLR))\n",
    "PLR1=list(map('{:.2f}'.format,map(float,(PLR))))\n",
    "print(\"Positive likelihood ratio:\")\n",
    "print(PLR)\n",
    "#Negative likelihood ratio\n",
    "NLR = FNR/TNR\n",
    "NLR1=list(map('{:.2f}'.format,map(float,(NLR))))\n",
    "print(\"Negative Likelihood ratio\")\n",
    "print(NLR)\n",
    "plt.plot(TPR,FPR)\n",
    "plt.show()\n",
    "names = ['HE', 'BBT', 'WBH', 'FH', 'WG']\n",
    "titles = ['CLASS', 'FPR', 'FNR', 'TPR','TNR','Specifity','Neg Precision','Pos Likelihood\n",
    "Ratio','Neg Likelihood Ratio']\n",
    "data = [titles] + list(zip(names,FPR1, FNR1, TPR1,TNR1,Specifity1,NPV1,PLR1,NLR1))\n",
    "for i, d in enumerate(data):\n",
    "line = '|'.join(str(x).ljust(12) for x in d)\n",
    "print(line)\n",
    "if i == 0:\n",
    "print('‐' * len(line))\n",
    "import fpdf\n",
    "pdf = fpdf.FPDF(format='letter')\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=8)\n",
    "for i in data:\n",
    "pdf.write(5, str(i))\n",
    "pdf.ln()\n",
    "pdf.output(\"testings.pdf\")\n",
    "##plt.plot(np.sort(FPR)) # Sorted in ascending order\n",
    "##plt.plot(np.sort(FNR)[::‐1]) # Sorted in descending order\n",
    "##plt.xlabel('False Positive Rate')\n",
    "##plt.ylabel('True Positive Rate')\n",
    "##plt.title('ROC CURVE')\n",
    "##\n",
    "##plt.show()\n",
    "print(\"Confusion matrix for test set using SVM\")\n",
    "print(cm_test)\n",
    "def total_count(y):\n",
    "count = np.zeros(5)\n",
    "for i in range(y.size):\n",
    "if (y[i] == 0):\n",
    "count[0] += 1\n",
    "if (y[i] == 1):\n",
    "count[1] += 1\n",
    "if (y[i] == 2):\n",
    "count[2] += 1\n",
    "if (y[i] == 3):\n",
    "count[3] += 1\n",
    "if (y[i] == 4):\n",
    "count[4] += 1\n",
    "if (y[i] == 5):\n",
    "count[5] += 1\n",
    "return count\n",
    "def pre_rec(cm, count):\n",
    "perc = []\n",
    "for i in range(5):\n",
    "perc.append(float(\"{0:.2f}\".format(cm[i][i] / count[i] * 100)))\n",
    "return perc\n",
    "def overall_accuracy(cm, test_labels):\n",
    "sum = 0\n",
    "for i in range(5):\n",
    "sum += cm[i][i]\n",
    "return float(\"{0:.2f}\".format(sum * 100.0 / test_labels.size))\n",
    "y_test_count = total_count(test_labels)\n",
    "y_pred_count_svmk = total_count(y_pred)\n",
    "recall_svmk = pre_rec(cm_test / 100, y_test_count)\n",
    "precision_svmk = pre_rec(cm_test / 100, y_pred_count_svmk)\n",
    "accuracy_svmk = overall_accuracy(cm_test, test_labels)\n",
    "print(\"Precision for SVM: \")\n",
    "print(precision_svmk)\n",
    "print(\"Recall for SVM: \")\n",
    "print(recall_svmk)\n",
    "print(\"Accuracy for SVM: \")\n",
    "print(accuracy_svmk)\n",
    "from sklearn import metrics\n",
    "classification_report = metrics.classification_report(test_labels, y_pred)\n",
    "# store report in results\n",
    "print(classification_report)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plot_classification_report(cr, title='Classification report ', with_avg_total=False,\n",
    "cmap=plt.cm.Blues):\n",
    "lines = cr.split('\\n')\n",
    "classes = []\n",
    "plotMat = []\n",
    "for line in lines[2: (len(lines) ‐ 3)]:\n",
    "# print(line)\n",
    "t = line.split()\n",
    "# print(t)\n",
    "# print(line) t = line.split() # print(t)\n",
    "if len(t) == 0:\n",
    "break\n",
    "classes.append(t[0])\n",
    "v = [float(x) for x in t[1: len(t) ‐ 1]]\n",
    "print(v)\n",
    "plotMat.append(v)\n",
    "if with_avg_total:\n",
    "aveTotal = lines[len(lines) ‐ 1].split()\n",
    "classes.append('avg/total')\n",
    "vAveTotal = [float(x) for x in t[1:len(aveTotal) ‐ 1]]\n",
    "plotMat.append(vAveTotal)\n",
    "plt.imshow(plotMat, interpolation='nearest', cmap=cmap)\n",
    "plt.title(title)\n",
    "plt.colorbar()\n",
    "x_tick_marks = np.arange(3)\n",
    "y_tick_marks = np.arange(len(classes))\n",
    "plt.xticks(x_tick_marks, ['precision', 'recall', 'f1‐score'], rotation=45)\n",
    "plt.yticks(y_tick_marks, classes)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Classes')\n",
    "plt.xlabel('Measures')\n",
    "plt.savefig(\"tablepdf.pdf\", bbox_inches='tight')\n",
    "plot_classification_report(classification_report)\n",
    "print(\"Confusion matrix for train set using SVM\")\n",
    "print(cm_train)\n",
    "print(\"Kernel = rbf\")\n",
    "print()\n",
    "print('Accuracy for training set for SVM using SVM = {}'.format((np.trace(cm_train)) /\n",
    "len(train_labels)))\n",
    "print('Accuracy for test set for SVM using SVM= {}'.format((np.trace(cm_test)) /\n",
    "len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
